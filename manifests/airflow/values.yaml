airflowVersion: "2.9.1"

executor: KubernetesExecutor

airflow:
  users:
    - username: admin
      password: admin
      role: Admin
      email: admin@example.com

webserver:
  enabled: true
  replicas: 1
  port: 8080
  service:
    type: NodePort
    nodePort: 30080
  persistence:
    enabled: false
  waitForMigrations:
    enabled: false
    securityContexts:
      container: {}
  podDisruptionBudget:
    enabled: false
  livenessProbe:
    enabled: true
    initialDelaySeconds: 60
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    scheme: HTTP
    path: /health
    port: 8080
  readinessProbe:
    enabled: true
    initialDelaySeconds: 60
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    scheme: HTTP
    path: /health
    port: 8080
  startupProbe:
    enabled: true
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5
    scheme: HTTP
    path: /health
    port: 8080
  defaultUser:
    enabled: true
    role: Admin
    username: admin
    email: admin@example.com
    firstName: admin
    lastName: user
    password: admin
  securityContexts:
    pod: {}
    container: {}
  serviceAccount:
    create: true
  hpa:
    enabled: false

config:
  core:
    dags_folder: '{{ include "airflow_dags" . }}'
    # This is ignored when used with the official Docker image
    load_examples: 'False'
    executor: '{{ .Values.executor }}'
    # For Airflow 1.10, backward compatibility; moved to [logging] in 2.0
    colored_console_log: 'False'
    remote_logging: '{{- ternary "True" "False" (or .Values.elasticsearch.enabled .Values.opensearch.enabled) }}'
    auth_manager: "airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager"
  logging:
    remote_logging: '{{- ternary "True" "False" (or .Values.elasticsearch.enabled .Values.opensearch.enabled) }}'
    colored_console_log: 'False'
  metrics:
    statsd_on: '{{ ternary "True" "False" .Values.statsd.enabled }}'
    statsd_port: 9125
    statsd_prefix: airflow
    statsd_host: '{{ printf "%s-statsd" (include "airflow.fullname" .) }}'
  fab:
    enable_proxy_fix: 'True'
  webserver:
    # For Airflow 2.X
    enable_proxy_fix: 'True'
    # For Airflow 1.10
    rbac: 'True'
  celery:
    flower_url_prefix: '{{ ternary "" .Values.ingress.flower.path (eq .Values.ingress.flower.path "/") }}'
    worker_concurrency: 16
  scheduler:
    standalone_dag_processor: '{{ ternary "True" "False" (or (semverCompare ">=3.0.0" .Values.airflowVersion) (.Values.dagProcessor.enabled | default false)) }}'
    # statsd params included for Airflow 1.10 backward compatibility; moved to [metrics] in 2.0
    statsd_on: '{{ ternary "True" "False" .Values.statsd.enabled }}'
    statsd_port: 9125
    statsd_prefix: airflow
    statsd_host: '{{ printf "%s-statsd" (include "airflow.fullname" .) }}'
    # `run_duration` included for Airflow 1.10 backward compatibility; removed in 2.0.
    run_duration: 41460
  elasticsearch:
    json_format: 'True'
    log_id_template: "{dag_id}_{task_id}_{execution_date}_{try_number}"
  elasticsearch_configs:
    max_retries: 3
    timeout: 30
    retry_timeout: 'True'
  kerberos:
    keytab: '{{ .Values.kerberos.keytabPath }}'
    reinit_frequency: '{{ .Values.kerberos.reinitFrequency }}'
    principal: '{{ .Values.kerberos.principal }}'
    ccache: '{{ .Values.kerberos.ccacheMountPath }}/{{ .Values.kerberos.ccacheFileName }}'
  celery_kubernetes_executor:
    kubernetes_queue: 'kubernetes'
  # The `kubernetes` section is deprecated in Airflow >= 2.5.0 due to an airflow.cfg schema change.
  # The `kubernetes` section can be removed once the helm chart no longer supports Airflow < 2.5.0.
  kubernetes:
    namespace: '{{ .Release.Namespace }}'
    # The following `airflow_` entries are for Airflow 1, and can be removed when it is no longer supported.
    airflow_configmap: '{{ include "airflow_config" . }}'
    airflow_local_settings_configmap: '{{ include "airflow_config" . }}'
    pod_template_file: '{{ include "airflow_pod_template_file" . }}/pod_template_file.yaml'
    worker_container_repository: '{{ .Values.images.airflow.repository | default .Values.defaultAirflowRepository }}'
    worker_container_tag: '{{ .Values.images.airflow.tag | default .Values.defaultAirflowTag }}'
    multi_namespace_mode: '{{ ternary "True" "False" .Values.multiNamespaceMode }}'
  # The `kubernetes_executor` section duplicates the `kubernetes` section in Airflow >= 2.5.0 due to an airflow.cfg schema change.
  kubernetes_executor:
    namespace: '{{ .Release.Namespace }}'
    pod_template_file: '{{ include "airflow_pod_template_file" . }}/pod_template_file.yaml'
    worker_container_repository: '{{ .Values.images.airflow.repository | default .Values.defaultAirflowRepository }}'
    worker_container_tag: '{{ .Values.images.airflow.tag | default .Values.defaultAirflowTag }}'
    multi_namespace_mode: '{{ ternary "True" "False" .Values.multiNamespaceMode }}'
    
scheduler:
  enabled: true
  #  hostAliases for the scheduler pod
  hostAliases: []
  #  - ip: "127.0.0.1"
  #    hostnames:
  #      - "foo.local"
  #  - ip: "10.1.2.3"
  #    hostnames:
  #      - "foo.remote"

  # If the scheduler stops heartbeating for 5 minutes (5*60s) kill the
  # scheduler and let Kubernetes restart it
  livenessProbe:
    initialDelaySeconds: 10
    timeoutSeconds: 20
    failureThreshold: 5
    periodSeconds: 60
    command: ~

  # Wait for at most 1 minute (6*10s) for the scheduler container to startup.
  # livenessProbe kicks in after the first successful startupProbe
  startupProbe:
    initialDelaySeconds: 0
    failureThreshold: 6
    periodSeconds: 10
    timeoutSeconds: 20
    command: ~

  # Airflow 2.0 allows users to run multiple schedulers,
  # However this feature is only recommended for MySQL 8+ and Postgres
  replicas: 1
  # Max number of old replicasets to retain
  revisionHistoryLimit: ~

  # Command to use when running the Airflow scheduler (templated).
  command: ~
  # Args to use when running the Airflow scheduler (templated).
  args: ["bash", "-c", "exec airflow scheduler"]

  # Update Strategy when scheduler is deployed as a StatefulSet
  # (when using LocalExecutor and workers.persistence)
  updateStrategy: ~
  # Update Strategy when scheduler is deployed as a Deployment
  # (when not using LocalExecutor and workers.persistence)
  strategy: ~

  # When not set, the values defined in the global securityContext will be used
  # (deprecated, use `securityContexts` instead)
  securityContext: {}
  #  runAsUser: 50000
  #  fsGroup: 0
  #  runAsGroup: 0

  # Detailed default security context for scheduler deployments for container and pod level
  securityContexts:
    pod: {}
    container: {}

  # container level lifecycle hooks
  containerLifecycleHooks: {}

  # Grace period for tasks to finish after SIGTERM is sent from kubernetes
  terminationGracePeriodSeconds: 10

  # Create ServiceAccount
  serviceAccount:
    # only affect CeleryExecutor, default value is true
    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
    automountServiceAccountToken: true
    # Specifies whether a ServiceAccount should be created
    create: true
    # The name of the ServiceAccount to use.
    # If not set and create is true, a name is generated using the release name
    name: ~

    # Annotations to add to scheduler kubernetes service account.
    annotations: {}

  # Scheduler pod disruption budget
  podDisruptionBudget:
    enabled: false

    # PDB configuration
    config:
      # minAvailable and maxUnavailable are mutually exclusive
      maxUnavailable: 1
      # minAvailable: 1

  resources: {}
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi

  # This setting tells kubernetes that its ok to evict
  # when it wants to scale a node down.
  safeToEvict: true

  # Launch additional containers into scheduler (templated).
  extraContainers: []
  # Add additional init containers into scheduler (templated).
  extraInitContainers: []

  # Mount additional volumes into scheduler. It can be templated like in the following example:
  #   extraVolumes:
  #     - name: my-templated-extra-volume
  #       secret:
  #          secretName: '{{ include "my_secret_template" . }}'
  #          defaultMode: 0640
  #          optional: true
  #
  #   extraVolumeMounts:
  #     - name: my-templated-extra-volume
  #       mountPath: "{{ .Values.my_custom_path }}"
  #       readOnly: true
  extraVolumes: []
  extraVolumeMounts: []

  # Select certain nodes for airflow scheduler pods.
  nodeSelector: {}
  affinity: {}
  # default scheduler affinity is:
  #  podAntiAffinity:
  #    preferredDuringSchedulingIgnoredDuringExecution:
  #    - podAffinityTerm:
  #        labelSelector:
  #          matchLabels:
  #            component: scheduler
  #        topologyKey: kubernetes.io/hostname
  #      weight: 100
  tolerations: []
  topologySpreadConstraints: []

  priorityClassName: ~

  # annotations for scheduler deployment
  annotations: {}

  podAnnotations: {}

  # Labels specific to scheduler objects and pods
  labels: {}

  logGroomerSidecar:
    # Whether to deploy the Airflow scheduler log groomer sidecar.
    enabled: false
    # Command to use when running the Airflow scheduler log groomer sidecar (templated).
    command: ~
    # Args to use when running the Airflow scheduler log groomer sidecar (templated).
    args: ["bash", "/clean-logs"]
    # Number of days to retain logs
    retentionDays: 15
    # frequency to attempt to groom logs, in minutes
    frequencyMinutes: 15
    resources: {}
    #  limits:
    #   cpu: 100m
    #   memory: 128Mi
    #  requests:
    #   cpu: 100m
    #   memory: 128Mi
    # Detailed default security context for logGroomerSidecar for container level
    securityContexts:
      container: {}
    # container level lifecycle hooks
    containerLifecycleHooks: {}
    env: []

  waitForMigrations:
    # Whether to create init container to wait for db migrations
    enabled: true
    env: []
    # Detailed default security context for waitForMigrations for container level
    securityContexts:
      container: {}

  env: []

triggerer:
  enabled: true
  replicas: 1
  keda:
    enabled: false
  logGroomerSidecar:
    enabled: false
    containerLifecycleHooks: {}
    securityContexts:
      container: {}
  livenessProbe:
    initialDelaySeconds: 10
    timeoutSeconds: 20
    failureThreshold: 5
    periodSeconds: 60
    command: []
  waitForMigrations:
    enabled: false
    securityContexts:
      container: {}
  serviceAccount:
    create: true
  securityContexts:
    pod: {}
    container: {}
  persistence:
    enabled: false

workers:
  keda:
    enabled: true
    minReplicaCount: 1
    maxReplicaCount: 10
    pollingInterval: 30
    cooldownPeriod: 300
  persistence:
    enabled: false
  serviceAccount:
    create: true
  hpa:
    enabled: false

dags:
  persistence:
    enabled: false
  gitSync:
    enabled: true
    repo: https://github.com/sserkanguzel/your-dag-repo.git
    branch: main
    subPath: dags
    depth: 1
    syncInterval: 60
    credentials:
      username: ""
      password: ""
    securityContexts:
      pod: {}
      container: {}

dagProcessor:
  enabled: ~
  replicas: 1
  revisionHistoryLimit: ~
  args: ["bash", "-c", "exec airflow dag-processor"]
  strategy:
    rollingUpdate:
      maxSurge: "100%"
      maxUnavailable: "50%"
  livenessProbe:
    initialDelaySeconds: 10
    timeoutSeconds: 20
    failureThreshold: 5
    periodSeconds: 60
    command: ~
  serviceAccount:
    create: true
  securityContexts:
    pod: {}
    container: {}
  containerLifecycleHooks: {}
  resources: {}
  terminationGracePeriodSeconds: 60
  safeToEvict: true
  extraContainers: []
  extraInitContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  nodeSelector: {}
  affinity: {}
  tolerations: []
  topologySpreadConstraints: []
  priorityClassName: ~
  logGroomerSidecar:
    enabled: false
    command: ~
    args: ["bash", "/clean-logs"]
    retentionDays: 15
    frequencyMinutes: 15
    resources: {}
    securityContexts:
      container: {}
    env: []
  waitForMigrations:
    enabled: false
    env: []
    securityContexts:
      container: {}
  env: []

logs:
  persistence:
    enabled: false

postgresql:
  enabled: true
  auth:
    username: airflow
    password: airflow
    database: airflow
  persistence:
    enabled: true
    storageClass: "local-path"
    size: 8Gi

data:
  metadataConnection:
    protocol: "postgresql"
    user: "airflow"
    pass: "airflow"
    host: "postgresql"
    port: 5432
    database: "airflow"
    query: "sslmode=disable"

redis:
  enabled: true  
  serviceAccount:
    create: true

flower:
  enabled: false

ingress:
  enabled: false
  web:
    enabled: false
  flower:
    enabled: false
  apiServer:
    enabled: false
  statsd:
    enabled: false
  pgbouncer:
    enabled: false

namespace: airflow

ports:
  pgbouncer: 6432

createUserJob:
  enabled: true
  useHelmHooks: false
  applyCustomEnv: false
  serviceAccount:
    create: true
    automountServiceAccountToken: true
  securityContexts:
    pod: {}
    container: {}
  jobAnnotations: {}
  labels: {}

migrateDatabaseJob:
  enabled: true
  useHelmHooks: false
  applyCustomEnv: false
  serviceAccount:
    create: true
  securityContexts:
    pod: {}
    container: {}
  jobAnnotations: {}
  labels: {}

enableBuiltInSecretEnvVars:
  AIRFLOW__CORE__FERNET_KEY: true
  AIRFLOW__CORE__SQL_ALCHEMY_CONN: true
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: true
  AIRFLOW_CONN_AIRFLOW_DB: true
  AIRFLOW__API_AUTH__JWT_SECRET: true
  AIRFLOW__WEBSERVER__SECRET_KEY: true
  AIRFLOW__CELERY__CELERY_RESULT_BACKEND: true
  AIRFLOW__CELERY__RESULT_BACKEND: true
  AIRFLOW__CELERY__BROKER_URL: true
  AIRFLOW__ELASTICSEARCH__HOST: true
  AIRFLOW__ELASTICSEARCH__ELASTICSEARCH_HOST: true
  AIRFLOW__OPENSEARCH__HOST: true

securityContexts:
  pod: {}
  container: {}

networkPolicies: 
  enabled: false

pgbouncer:
  enabled: false
  ssl:
    ca: ""
    cert: ""
    key: ""
  serviceAccount:
    create: true

kerberos:
  enabled: false

registry:
  secretName: ""

elasticsearch:
  enabled: false

opensearch:
  enabled: false

statsd:
  enabled: false

rbac:
  create: true

apiServer:
  allowPodLogReading: true
  serviceAccount:
    create: true

cleanup:
  enabled: false
  serviceAccount:
    create: true

multiNamespaceMode: false

images:
  airflow:
    repository: apache/airflow
    tag: 2.9.1
  gitSync:
    repository: k8s.gcr.io/git-sync/git-sync
    tag: v3.6.3
