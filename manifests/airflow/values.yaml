airflowVersion: "2.9.1"

executor: KubernetesExecutor

airflow:
  users:
    - username: admin
      password: admin
      role: Admin
      email: admin@example.com

webserver:
  enabled: true
  replicas: 1
  port: 8080
  service:
    type: NodePort
    nodePort: 30080  # Optional: choose a specific port or remove to auto-assign
  persistence:
    enabled: false
  waitForMigrations: # Ensure Airflow starts only after DB schema is up-to-date. 
    enabled: false
    securityContexts:
      container: {} 
  podDisruptionBudget: # How many pods of a particular application can be down at the same time during voluntary disruptions
    enabled: false
  livenessProbe: # Kubernetes mechanism to check if a pod is healthy
    enabled: true
    initialDelaySeconds: 60
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    scheme: HTTP
    path: /health
    port: 8080
  readinessProbe: # Tells Kubernetes when the pod is ready to accept traffic.
    enabled: true
    initialDelaySeconds: 60
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    scheme: HTTP
    path: /health
    port: 8080
  startupProbe: # Checks if the app inside the pod has started properly
    enabled: true
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5
    scheme: HTTP
    path: /health
    port: 8080
  defaultUser:
    enabled: true
    role: Admin
    username: admin
    email: admin@example.com
    firstName: admin
    lastName: user
    password: admin
  securityContexts:
    pod: {}
    container: {}
  serviceAccount: ## Service Account: In Kubernetes, a ServiceAccount provides an identity for pods to interact with the Kubernetes API
    create: true
  hpa: ## hpa: Horizontal Pod AutoScaler
    enabled: false
  
config:
  webserver:
    base_url: "http://localhost:8080"
  core:
    dags_folder: "/opt/airflow/dags"
    load_examples: "False"
  logging:
  remote_logging:

scheduler:
  enabled: true
  replicas: 1
  waitForMigrations: # Ensure Airflow starts only after DB schema is up-to-date. 
    enabled: false
    securityContexts:
      container: {}
  podDisruptionBudget: # How many pods of a particular application can be down at the same time during voluntary disruptions
    enabled: false
  logGroomerSidecar: # Whether to deploy the Airflow triggerer log groomer sidecar.
    enabled: false
    containerLifecycleHooks: {}
    securityContexts:
      container: {}
  livenessProbe:
    initialDelaySeconds: 10
    timeoutSeconds: 20
    failureThreshold: 5
    periodSeconds: 60
    command: ~
  startupProbe:
    initialDelaySeconds: 0
    failureThreshold: 6
    periodSeconds: 10
    timeoutSeconds: 20
    command: ~
  securityContexts:
    pod: {}
    container: {}
  serviceAccount: ## Service Account: In Kubernetes, a ServiceAccount provides an identity for pods to interact with the Kubernetes API
    create: true

triggerer:
  enabled: true
  replicas: 1
  keda:
    enabled: false
  logGroomerSidecar: # Whether to deploy the Airflow triggerer log groomer sidecar.
    enabled: false
    containerLifecycleHooks: {}
    securityContexts:
      container: {}
  livenessProbe:  # If the triggerer stops heartbeating for 5 minutes (5*60s) kill the triggerer and let Kubernetes restart it
    initialDelaySeconds: 10
    timeoutSeconds: 20
    failureThreshold: 5
    periodSeconds: 60
    command: ~
  waitForMigrations: # Ensure Airflow starts only after DB schema is up-to-date. 
    enabled: false
    securityContexts:
      container: {}
  serviceAccount:
    create: true
  securityContexts:
    pod: {}
    container: {}
  persistence:
    enabled: false

workers:
  keda:
    enabled: true
    minReplicaCount: 1
    maxReplicaCount: 10
    pollingInterval: 30
    cooldownPeriod: 300
  persistence:
    enabled: false
  serviceAccount:
    create: true
  hpa:
    enabled: false
    
dags:
  persistence:
    enabled: false
  gitSync:
    enabled: true
    repo: https://github.com/sserkanguzel/your-dag-repo.git
    branch: main
    subPath: dags   # adjust if your DAGs are in a subfolder
    depth: 1
    syncInterval: 60
    credentials:
      username: ""   # Leave blank if public repo
      password: ""   # Or use `existingSecret` if private
    securityContexts:
      pod: {}
      container: {}
      
dagProcessor: ## responsible for parsing, processing, and managing DAG files 
  enabled: true
  replicas: 1
  args: ["bash", "-c", "exec airflow dag-processor"]
  strategy:
    rollingUpdate:
      maxSurge: "100%"
      maxUnavailable: "50%"
  livenessProbe:
    initialDelaySeconds: 10
    timeoutSeconds: 20
    failureThreshold: 5
    periodSeconds: 60
    command: ~
  serviceAccount:
    create: true
    automountServiceAccountToken: true
  securityContexts:
    pod: {}
    container: {}
  terminationGracePeriodSeconds: 60
  safeToEvict: true
  logGroomerSidecar:
    enabled: false
    securityContexts:
      container: {}
  waitForMigrations:
    enabled: false
    securityContexts:
      container: {}
  env: []
      
logs:
  persistence:
    enabled: false

postgresql:
  enabled: true
  auth:
    username: airflow
    password: airflow
    database: airflow
  persistence:
    enabled: true
    storageClass: "local-path"
    size: 8Gi

data:
  metadataConnection:
    protocol: "postgresql"
    user: "airflow"
    pass: "airflow"
    host: "postgresql"
    port: 5432
    database: "airflow"
    query: "sslmode=disable"

redis:
  enabled: true  
  serviceAccount:
    create: true

flower:
  enabled: false

ingress:
  enabled: false  # We're using NodePort instead
  web:
    enabled: false
  flower:
    enabled: false
  apiServer:
    enabled: false
  statsd:
    enabled: false
  pgbouncer:
    enabled: false
    
namespace: airflow

ports:
  pgbouncer: 6432

createUserJob: ## Kubernetes Job that automatically creates a default user (typically an admin) in the Airflow metadata database when the chart is installed.
  enabled: true
  useHelmHooks: false
  applyCustomEnv: false
  serviceAccount:
    create: true
    automountServiceAccountToken: true
  securityContexts:
    pod: {}
    container: {}
  jobAnnotations: {}
  labels: {}

migrateDatabaseJob:
  enabled: true
  useHelmHooks: false
  applyCustomEnv: false
  serviceAccount:
    create: true
  securityContexts:
    pod: {}
    container: {}
  jobAnnotations: {}
  labels: {}

enableBuiltInSecretEnvVars:
  AIRFLOW__CORE__FERNET_KEY: true
  AIRFLOW__CORE__SQL_ALCHEMY_CONN: true
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: true
  AIRFLOW_CONN_AIRFLOW_DB: true
  AIRFLOW__API_AUTH__JWT_SECRET: true
  AIRFLOW__WEBSERVER__SECRET_KEY: true
  AIRFLOW__CELERY__CELERY_RESULT_BACKEND: true
  AIRFLOW__CELERY__RESULT_BACKEND: true
  AIRFLOW__CELERY__BROKER_URL: true
  AIRFLOW__ELASTICSEARCH__HOST: true
  AIRFLOW__ELASTICSEARCH__ELASTICSEARCH_HOST: true
  AIRFLOW__OPENSEARCH__HOST: true
  
securityContexts: ## Security Context: Filesystem access, UID ID access etc configurations
  pod: {}
  container: {}
networkPolicies: 
  enabled: false
pgbouncer: # ## Security Context: Filesystem access, UID ID access etc configurations
  enabled: false
  ssl:
    ca: ""
    cert: ""
    key: ""
  serviceAccount: ## Service Account: In Kubernetes, a ServiceAccount provides an identity for pods to interact with the Kubernetes API
    create: true
kerberos: ## Airflow can optionally integrate with Kerberos for secure user authentication.
  enabled: false
registry: ## Used if pulling airflow images from a private registry
  secretName: ""
elasticsearch:
  enabled: false
opensearch:
  enabled: false
statsd: # StatsD collects metrics about Airflow components (like task durations, number of running tasks, scheduler performance).
  enabled: false
rbac: #  Role-Based Access Control
  create: true
apiServer: # This setting controls whether the Airflow API server allows podsâ€™ logs to be read via the API
  allowPodLogReading: true
  serviceAccount:
    create: true
cleanup: # Clean up old pods
  enabled: false
  serviceAccount:
    create: true
  
images:
  airflow:
    repository: apache/airflow
    tag: 2.9.1
  gitSync:
    repository: k8s.gcr.io/git-sync/git-sync
    tag: v3.6.3
