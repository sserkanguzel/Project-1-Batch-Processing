
apiVersion: v1
kind: Pod
metadata:
  name: airflow-worker-pod-template
  labels:
    app: airflow-worker
spec:
  # serviceAccountName: airflow-worker # Uncomment if your worker pods need a specific SA
  restartPolicy: Never # Task pods should not restart automatically after completion
  containers:
    - name: base # This *must* be named 'base' for the Kubernetes Executor
      image: "apache/airflow:2.7.1-python3.9" # <-- Crucial: Define the worker image from your values.yaml
      imagePullPolicy: IfNotPresent # Or Always, depending on your needs
      command: ["/entrypoint.sh"]
      env:
        # Essential environment variables for the worker container
        - name: AIRFLOW_IS_K8S_EXECUTOR_POD
          value: "True"
        - name: AIRFLOW__CORE__DAGS_FOLDER
          value: "/opt/airflow/dags/repo/dags"
        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
          value: postgresql+psycopg2://airflow:airflowpassword@postgres-postgresql.airflow.svc.cluster.local:5432/airflow_db
        - name: AIRFLOW__CORE__FERNET_KEY
          value: "bXKd_nJ7Yj0E309u7oh-cmXcFC89gi1IllSBl21Ku5g="
        - name: AIRFLOW__WEBSERVER__SECRET_KEY
          value: "Td_-CejX_6foYTgUzLXfrgVWvxlAuzp4Cemjf6J57b0"
      volumeMounts:
        # Mount the volume for DAGs so workers can find them
        - name: dags-volume
          mountPath: /opt/airflow/dags
          readOnly: true # Workers typically only need to read DAGs
  volumes:
    - name: dags-volume
      emptyDir: {} # This assumes DAGs are synced into an EmptyDir shared with workers
