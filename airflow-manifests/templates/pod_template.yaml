# kubernetes/airflow/config/pod_template.yaml
# This is the FULLY RESOLVED, STATIC YAML content for the Airflow worker pod template.
# It contains NO Helm templating ({{...}}) and is ready to be embedded in a ConfigMap.
apiVersion: v1
kind: Pod
metadata:
  name: dummy-name # This name is a placeholder for the template
spec:
  restartPolicy: Never
  # If your images require pull secrets, uncomment and specify them manually here
  # imagePullSecrets:
  #   - name: your-image-pull-secret
  serviceAccountName: airflow # Resolved from your values
  shareProcessNamespace: false # Resolved from your values

  # No nodeSelector, topologySpreadConstraints, affinity, tolerations, securityContext
  # blocks included here, as they resolved to empty based on typical default values.

  initContainers:
    # Git Sync container for fetching DAGs into each worker pod
    - name: git-sync
      image: "k8s.gcr.io/git-sync/git-sync:v3.6.9" # Resolved git-sync image
      env:
        - name: GIT_SYNC_REPO
          value: "https://github.com/sserkanguzel/Project-1-Batch-Processing.git" # Resolved repo URL
        - name: GIT_SYNC_BRANCH
          value: "main" # Resolved branch
        - name: GIT_SYNC_ROOT
          value: "/git"
        - name: GIT_SYNC_DEST
          value: "repo" # DAGs will be in /git/repo/dags
        - name: GIT_SYNC_SUBPATH
          value: "dags"
        - name: GIT_SYNC_ONE_TIME
          value: "true" # For worker pods, sync once and exit
      volumeMounts:
        - name: dags-volume
          mountPath: /git # git-sync mounts to /git

    # No initContainer for extraPipPackages as no value was provided for it.
    # No extraInitContainers as no value was provided for them.

  containers:
    - name: base # Crucial name for Kubernetes Executor
      image: "apache/airflow:2.7.1-python3.9" # Resolved Airflow worker image
      imagePullPolicy: IfNotPresent

      # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
      # !!! CRITICAL FIX: Explicitly set command. Do NOT include 'args:'      !!!
      # !!! The Kubernetes Executor will APPEND its task-specific arguments   !!!
      # !!! directly to this command, which is the standard Docker ENTRYPOINT.!!!
      # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
      command: ["/entrypoint.sh"]
      # No 'args:' line here!

      env:
        # Essential Airflow environment variables for worker operation
        - name: AIRFLOW__CORE__EXECUTOR
          value: LocalExecutor # KubernetesExecutor pods use LocalExecutor internally
        - name: AIRFLOW__CORE__DAGS_FOLDER
          value: "/opt/airflow/dags/repo/dags" # Path where DAGs are expected inside the worker pod
        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
          value: postgresql+psycopg2://airflow:airflowpassword@postgres-postgresql.airflow.svc.cluster.local:5432/airflow_db" # Resolved DB Conn
        - name: AIRFLOW__CORE__FERNET_KEY
          value: "bXKd_nJ7Yj0E309u7oh-cmXcFC89gi1IllSBl21Ku5g=" # Resolved Fernet Key
        - name: AIRFLOW__WEBSERVER__SECRET_KEY
          value: "Td_-CejX_6foYTgUzLXfrgVWvxlAuzp4Cemjf6J57b0" # Resolved Secret Key
        - name: CONNECTION_CHECK_MAX_COUNT
          value: "20" # Resolved from your template's env include

      ports: [] # As in your template

      resources: # Resolved resources for worker pods
        requests:
          cpu: "250m"
          memory: "512Mi"
        limits:
          cpu: "1000m"
          memory: "2Gi"

      volumeMounts:
        # Mount the DAGs volume for the base container
        - name: dags-volume
          mountPath: /opt/airflow/dags # Worker reads DAGs from here
          readOnly: true

    # No extraContainers as no value was provided for them.

  volumes:
    # Volume definition for DAGs
    - name: dags-volume
      emptyDir: {} # Assumed EmptyDir for DAGs
